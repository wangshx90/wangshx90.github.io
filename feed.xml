<feed xmlns="http://www.w3.org/2005/Atom"> <id>/</id><title>王书孝</title><subtitle>记录工作和学习中碰到的各种问题; 也是读书笔记；偶尔发发牢骚</subtitle> <updated>2022-04-12T09:50:39+08:00</updated> <author> <name>王书孝</name> <uri>/</uri> </author><link rel="self" type="application/atom+xml" href="/feed.xml"/><link rel="alternate" type="text/html" hreflang="zh-CN" href="/"/> <generator uri="https://jekyllrb.com/" version="4.2.2">Jekyll</generator> <rights> © 2022 王书孝 </rights> <icon>/assets/img/favicons/favicon.ico</icon> <logo>/assets/img/favicons/favicon-96x96.png</logo> <entry><title>golang中的io.Copy 和 ioutil.ReadAll</title><link href="/posts/golang-iocopy/" rel="alternate" type="text/html" title="golang中的io.Copy 和 ioutil.ReadAll" /><published>2021-02-04T17:00:00+08:00</published> <updated>2021-02-04T17:00:00+08:00</updated> <id>/posts/golang-iocopy/</id> <content src="/posts/golang-iocopy/" /> <author> <name>王书孝</name> </author> <category term="golang" /> <summary> golang中当我们需要拷贝数据时，常常用到 io.Copy 和 ioutil.ReadAll。那么这两个函数有什么区别，以及在何时应该用哪个呢？ ioutil.ReadAll 之所以把ReadAll单独拿出来讲，一来是因为我们经常需要把数据从某个 io.Reader对象读出来，二来也是因为它的性能问题常常被人吐槽。 先来看下它的使用场景。比如说，我们使用http.Client发送GET请求： func main() { res, err := http.Get("http://www.google.com/robots.txt") if err != nil { log.Fatal(err) } robots, err := io.ReadAll(res.Body) res.Body.Close() if err != nil { log.Fatal(e... </summary> </entry> <entry><title>Kafka原理学习之协议交互流程</title><link href="/posts/kafka-protocol/" rel="alternate" type="text/html" title="Kafka原理学习之协议交互流程" /><published>2021-02-04T17:00:00+08:00</published> <updated>2021-02-04T17:00:00+08:00</updated> <id>/posts/kafka-protocol/</id> <content src="/posts/kafka-protocol/" /> <author> <name>王书孝</name> </author> <category term="kafka" /> <summary> 要想理解某个系统是怎么运行的，首先我们可以看看它提供什么样的API。本文从 Kafka 的协议交互流程入手，分析 Producer 和 Consumer 是如何工作的。一方面，可以用来实现自己的 kafkasdk；另一方面也能更好地理解 Kafka 的内部原理。 接下来就从以下3个方面来学习Kafka协议： Kafka协议格式，包括编解码方案； Producer 工作流程； Consumer 工作流程 本文基于 Kafka 1.0 版本描述，较新版本(v2.7)肯定有出入，但核心逻辑没有改变 1 Kafka协议格式 这里主要参考 Kafka 官方提供的 KAFKA PROTOCOL GUIDE。如果你要自己实现 kafka Client，那么建议最好把它打印出来放在手边，一个字一个字地看 n 遍。 如果你只是想要了解 Producer 或者 Con... </summary> </entry> <entry><title>Kafka原理学习之消息时间戳</title><link href="/posts/learning-kafka-message-timestamps/" rel="alternate" type="text/html" title="Kafka原理学习之消息时间戳" /><published>2021-02-02T19:00:00+08:00</published> <updated>2021-02-02T19:00:00+08:00</updated> <id>/posts/learning-kafka-message-timestamps/</id> <content src="/posts/learning-kafka-message-timestamps/" /> <author> <name>王书孝</name> </author> <category term="kafka" /> <summary> 本文主要讲述kafka对消息时间戳提供的一些支持，以及kafka如何支持根据时间戳精确查找offset。 1 前言 得益于kafka良好的设计理念，Producer和Consumer完全独立，互不影响，各司其职即可。但是，对于消费者而言，当它从kafka拿到一条消息时，它可能会想知道，这条消息是何时发布到kafka的呢? 另外，当消费者开始消费时，除了从最新的offset或最久的offset开始之外，是不是可以允许消费者指定回退多长时间来开始消费呢？这在下面的两种场景下会非常有用： 为了保证数据的可靠性，我们通常在异地部署多个相互独立的kafka集群。当消费者从一个集群切到另一个集群时，由于offset不是全局的，所以我们期望切到新集群时，能够回退半小时，以保证消息不丢。 在同个集群内，当我们期望从一个ConsumerGroupId切到另外一个新的ConsumerG... </summary> </entry> </feed>
