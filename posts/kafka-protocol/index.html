<!DOCTYPE html><html lang="zh-CN" ><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><meta name="generator" content="Jekyll v4.2.2" /><meta property="og:title" content="Kafka原理学习之协议交互流程" /><meta property="og:locale" content="zh_CN" /><meta name="description" content="要想理解某个系统是怎么运行的，首先我们可以看看它提供什么样的API。本文从 Kafka 的协议交互流程入手，分析 Producer 和 Consumer 是如何工作的。一方面，可以用来实现自己的 kafkasdk；另一方面也能更好地理解 Kafka 的内部原理。" /><meta property="og:description" content="要想理解某个系统是怎么运行的，首先我们可以看看它提供什么样的API。本文从 Kafka 的协议交互流程入手，分析 Producer 和 Consumer 是如何工作的。一方面，可以用来实现自己的 kafkasdk；另一方面也能更好地理解 Kafka 的内部原理。" /><link rel="canonical" href="/posts/kafka-protocol/" /><meta property="og:url" content="/posts/kafka-protocol/" /><meta property="og:site_name" content="王书孝" /><meta property="og:type" content="article" /><meta property="article:published_time" content="2021-02-04T17:00:00+08:00" /><meta name="twitter:card" content="summary" /><meta property="twitter:title" content="Kafka原理学习之协议交互流程" /><meta name="twitter:site" content="@twitter_username" /> <script type="application/ld+json"> {"@context":"https://schema.org","@type":"BlogPosting","dateModified":"2021-02-04T17:00:00+08:00","datePublished":"2021-02-04T17:00:00+08:00","description":"要想理解某个系统是怎么运行的，首先我们可以看看它提供什么样的API。本文从 Kafka 的协议交互流程入手，分析 Producer 和 Consumer 是如何工作的。一方面，可以用来实现自己的 kafkasdk；另一方面也能更好地理解 Kafka 的内部原理。","headline":"Kafka原理学习之协议交互流程","mainEntityOfPage":{"@type":"WebPage","@id":"/posts/kafka-protocol/"},"url":"/posts/kafka-protocol/"}</script><title>Kafka原理学习之协议交互流程 | 王书孝</title><link rel="apple-touch-icon" sizes="180x180" href="/assets/img/favicons/apple-touch-icon.png"><link rel="icon" type="image/png" sizes="32x32" href="/assets/img/favicons/favicon-32x32.png"><link rel="icon" type="image/png" sizes="16x16" href="/assets/img/favicons/favicon-16x16.png"><link rel="manifest" href="/assets/img/favicons/site.webmanifest"><link rel="shortcut icon" href="/assets/img/favicons/favicon.ico"><meta name="apple-mobile-web-app-title" content="王书孝"><meta name="application-name" content="王书孝"><meta name="msapplication-TileColor" content="#da532c"><meta name="msapplication-config" content="/assets/img/favicons/browserconfig.xml"><meta name="theme-color" content="#ffffff"><link rel="preconnect" href="https://fonts.googleapis.com" ><link rel="dns-prefetch" href="https://fonts.googleapis.com" ><link rel="preconnect" href="https://fonts.gstatic.com" crossorigin><link rel="dns-prefetch" href="https://fonts.gstatic.com" crossorigin><link rel="preconnect" href="https://fonts.googleapis.com" ><link rel="dns-prefetch" href="https://fonts.googleapis.com" ><link rel="preconnect" href="https://cdn.jsdelivr.net" ><link rel="dns-prefetch" href="https://cdn.jsdelivr.net" ><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Lato&family=Source+Sans+Pro:wght@400;600;700;900&display=swap"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@4/dist/css/bootstrap.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.11.2/css/all.min.css"><link rel="stylesheet" href="/assets/css/style.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/afeld/bootstrap-toc@1.0.1/dist/bootstrap-toc.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/magnific-popup@1/dist/magnific-popup.min.css"> <script src="https://cdn.jsdelivr.net/npm/jquery@3/dist/jquery.min.js"></script> <script type="text/javascript"> class ModeToggle { static get MODE_KEY() { return "mode"; } static get MODE_ATTR() { return "data-mode"; } static get DARK_MODE() { return "dark"; } static get LIGHT_MODE() { return "light"; } static get ID() { return "mode-toggle"; } constructor() { if (this.hasMode) { if (this.isDarkMode) { if (!this.isSysDarkPrefer) { this.setDark(); } } else { if (this.isSysDarkPrefer) { this.setLight(); } } } let self = this; /* always follow the system prefers */ this.sysDarkPrefers.addEventListener("change", () => { if (self.hasMode) { if (self.isDarkMode) { if (!self.isSysDarkPrefer) { self.setDark(); } } else { if (self.isSysDarkPrefer) { self.setLight(); } } self.clearMode(); } self.notify(); }); } /* constructor() */ get sysDarkPrefers() { return window.matchMedia("(prefers-color-scheme: dark)"); } get isSysDarkPrefer() { return this.sysDarkPrefers.matches; } get isDarkMode() { return this.mode === ModeToggle.DARK_MODE; } get isLightMode() { return this.mode === ModeToggle.LIGHT_MODE; } get hasMode() { return this.mode != null; } get mode() { return sessionStorage.getItem(ModeToggle.MODE_KEY); } /* get the current mode on screen */ get modeStatus() { if (this.isDarkMode || (!this.hasMode && this.isSysDarkPrefer)) { return ModeToggle.DARK_MODE; } else { return ModeToggle.LIGHT_MODE; } } setDark() { $('html').attr(ModeToggle.MODE_ATTR, ModeToggle.DARK_MODE); sessionStorage.setItem(ModeToggle.MODE_KEY, ModeToggle.DARK_MODE); } setLight() { $('html').attr(ModeToggle.MODE_ATTR, ModeToggle.LIGHT_MODE); sessionStorage.setItem(ModeToggle.MODE_KEY, ModeToggle.LIGHT_MODE); } clearMode() { $('html').removeAttr(ModeToggle.MODE_ATTR); sessionStorage.removeItem(ModeToggle.MODE_KEY); } /* Notify another plugins that the theme mode has changed */ notify() { window.postMessage({ direction: ModeToggle.ID, message: this.modeStatus }, "*"); } } /* ModeToggle */ const toggle = new ModeToggle(); function flipMode() { if (toggle.hasMode) { if (toggle.isSysDarkPrefer) { if (toggle.isLightMode) { toggle.clearMode(); } else { toggle.setLight(); } } else { if (toggle.isDarkMode) { toggle.clearMode(); } else { toggle.setDark(); } } } else { if (toggle.isSysDarkPrefer) { toggle.setLight(); } else { toggle.setDark(); } } toggle.notify(); } /* flipMode() */ </script><body data-spy="scroll" data-target="#toc" data-topbar-visible="true"><div id="sidebar" class="d-flex flex-column align-items-end"><div class="profile-wrapper text-center"><div id="avatar"> <a href="/" alt="avatar" class="mx-auto"> <img src=" https://raw.githubusercontent.com/bookxiao/picsbed/main/common/avatar1.png " alt="avatar" onerror="this.style.display='none'"> </a></div><div class="site-title mt-3"> <a href="/">王书孝</a></div><div class="site-subtitle font-italic">一个普通程序猿的学习笔记</div></div><ul class="w-100"><li class="nav-item"> <a href="/" class="nav-link"> <i class="fa-fw fas fa-home ml-xl-3 mr-xl-3 unloaded"></i> <span>首页</span> </a><li class="nav-item"> <a href="/categories/" class="nav-link"> <i class="fa-fw fas fa-stream ml-xl-3 mr-xl-3 unloaded"></i> <span>分类</span> </a><li class="nav-item"> <a href="/tags/" class="nav-link"> <i class="fa-fw fas fa-tag ml-xl-3 mr-xl-3 unloaded"></i> <span>标签</span> </a><li class="nav-item"> <a href="/archives/" class="nav-link"> <i class="fa-fw fas fa-archive ml-xl-3 mr-xl-3 unloaded"></i> <span>归档</span> </a><li class="nav-item"> <a href="/about/" class="nav-link"> <i class="fa-fw fas fa-info-circle ml-xl-3 mr-xl-3 unloaded"></i> <span>关于</span> </a></ul><div class="sidebar-bottom mt-auto d-flex flex-wrap justify-content-center align-items-center"> <button class="mode-toggle btn" aria-label="Switch Mode"> <i class="fas fa-adjust"></i> </button> <span class="icon-border"></span> <a href="https://github.com/bookxiao" aria-label="github" target="_blank" rel="noopener"> <i class="fab fa-github"></i> </a> <a href="https://twitter.com/twitter_username" aria-label="twitter" target="_blank" rel="noopener"> <i class="fab fa-twitter"></i> </a> <a href=" javascript:location.href = 'mailto:' + ['shuxiao90','qq.com'].join('@')" aria-label="email" > <i class="fas fa-envelope"></i> </a> <a href="/feed.xml" aria-label="rss" > <i class="fas fa-rss"></i> </a></div></div><div id="topbar-wrapper" class="row justify-content-center"><div id="topbar" class="col-11 d-flex h-100 align-items-center justify-content-between"> <span id="breadcrumb"> <span> <a href="/"> 首页 </a> </span> <span>Kafka原理学习之协议交互流程</span> </span> <i id="sidebar-trigger" class="fas fa-bars fa-fw"></i><div id="topbar-title"> 文章</div><i id="search-trigger" class="fas fa-search fa-fw"></i> <span id="search-wrapper" class="align-items-center"> <i class="fas fa-search fa-fw"></i> <input class="form-control" id="search-input" type="search" aria-label="search" autocomplete="off" placeholder="搜索..."> </span> <span id="search-cancel" >取消</span></div></div><div id="main-wrapper"><div id="main"><div class="row"><div id="core-wrapper" class="col-12 col-lg-11 col-xl-8"><div class="post pl-1 pr-1 pl-sm-2 pr-sm-2 pl-md-4 pr-md-4"><h1 data-toc-skip>Kafka原理学习之协议交互流程</h1><div class="post-meta text-muted"><div> 作者 <em> <a href="https://github.com/bookxiao">王书孝</a> </em></div><div class="d-flex"><div> <span> 发表于 <em class="timeago" data-ts="1612429200" data-toggle="tooltip" data-placement="bottom" data-tooltip-df="llll" > 2021-02-04 </em> </span> <span class="readtime" data-toggle="tooltip" data-placement="bottom" title="6585 字"> <em>36 分钟</em>阅读</span></div></div></div><div class="post-content"><p>要想理解某个系统是怎么运行的，首先我们可以看看它提供什么样的API。本文从 Kafka 的协议交互流程入手，分析 Producer 和 Consumer 是如何工作的。一方面，可以用来实现自己的 kafkasdk；另一方面也能更好地理解 Kafka 的内部原理。</p><p>接下来就从以下3个方面来学习Kafka协议：</p><ul><li>Kafka协议格式，包括编解码方案；<li>Producer 工作流程；<li>Consumer 工作流程</ul><blockquote><p>本文基于 Kafka 1.0 版本描述，较新版本(v2.7)肯定有出入，但核心逻辑没有改变</p></blockquote><h2 id="1-kafka协议格式"><span class="mr-2">1 Kafka协议格式</span><a href="#1-kafka协议格式" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2></h2><p>这里主要参考 Kafka 官方提供的 <a href="http://kafka.apache.org/protocol.html">KAFKA PROTOCOL GUIDE</a>。如果你要自己实现 kafka Client，那么建议最好把它打印出来放在手边，一个字一个字地看 n 遍。</p><p>如果你只是想要了解 Producer 或者 Consumer 的工作流程，那么只需要看看我接下来总结的内容即可。</p><p>Kafka协议可以分为 <em>Request</em> 和 <em>Response</em>。</p><p><img data-src="https://raw.githubusercontent.com/bookxiao/picsbed/main/kafka/req_resp.png" alt="Req&amp;Resp" data-proofer-ignore></p><p>从某种程度来说，Kafka更多的是提供了 <em>RPC</em> 功能：请求只能由 Client 主动发到 Broker；Broker 针对每个请求回复一个响应给 Client。</p><p>不同的 Request 使用不同的 <code class="language-plaintext highlighter-rouge">apikey</code> 来区分；Request 和 Response 通过 <code class="language-plaintext highlighter-rouge">CorrleationId</code> 来一一对应。</p><h3 id="编解码方案"><span class="mr-2">编解码方案</span><a href="#编解码方案" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3></h3><p>从编解码角度来说，每个协议包都是由 4字节的 <em>size</em> 开头，后面再跟相应字节的请求包或响应包。</p><p>在1.0及以前版本中，Kafka协议中可使用的数据类型仅有3种：</p><ul><li>固定长度的整形，包括 <em>int8, int16, int32, int64</em> 等；<li>可变长度的字符串，包括 <em>string, bytes</em> 等；<li>复合类型，包括 <em>array</em> 等。</ul><p>每种类型都有特定的编解码方案，具体可以参考官方文档，这里不再详述。</p><p>从2.0版本开始，又增加了很多复杂的类型，比如 <em>boolean, varint, varlong, uuid, float64, compact_string, compact_bytes</em> 等等。</p><h3 id="request--response"><span class="mr-2">Request &amp; Response</span><a href="#request--response" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3></h3><p>Kafka最新版本中提供的Request已经达到50多种了，但是比较核心的其实也就下面几种：</p><div class="table-wrapper"><table><thead><tr><th>请求<th>说明<tbody><tr><td>Metadata<td>查询集群当前Broker列表，以及指定的topic信息，包括partition数量以及leader/replicas信息<tr><td>Produce<td>发布消息<tr><td>Fetch<td>从指定偏移量开始拉取某个（些）partition的消息<tr><td>Offset<td>查询某个（些）partition的offset信息，可以指定时间戳<tr><td>Offset Commit<td>提交offset，只针对ConsumerGroup<tr><td>Offset Fetch<td>查询某个ConsumerGroup当前提交的offset信息</table></div><p>此外，从0.9版本开始，Kafka提供了消费组的概念，并相应地提供了一组管理协议，包括 <em>GroupCoordinator/JoinGroup/SyncGroup/LeaveGroup/Heartbeat</em> 等，具体在后面的Consumer流程中再讲。</p><h4 id="request"><span class="mr-2">Request</span><a href="#request" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h4></h4><p>每个请求都有固定的 <em>header</em>，具体格式如下：</p><div class="language-cpp highlighter-rouge"><div class="code-header"> <span data-label-text="Cpp"><i class="fas fa-code small"></i></span> <button aria-label="copy" data-title-succeed="已复制！"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
</pre><td class="rouge-code"><pre><span class="k">struct</span> <span class="nc">RequestHeader</span> <span class="p">{</span>
    <span class="kt">int32_t</span> <span class="n">size</span><span class="p">;</span> <span class="c1">// 请求总长度</span>
    <span class="kt">int16_t</span> <span class="n">apikey</span><span class="p">;</span> <span class="c1">// 区分请求类型</span>
    <span class="kt">int16_t</span> <span class="n">version</span><span class="p">;</span> <span class="c1">// 区分请求版本</span>
    <span class="kt">int32_t</span> <span class="n">correlationId</span><span class="p">;</span> <span class="c1">// 请求上下文，用于对应回包</span>
    <span class="n">std</span><span class="o">::</span><span class="n">string</span> <span class="n">clientid</span><span class="p">;</span> <span class="c1">// 请求方标识，仅用来打日志</span>
<span class="p">};</span>
</pre></table></code></div></div><p>在具体发包时，header 在前（这不废话吗！），后面再跟具体的请求包。请求包的大小等于总的 size 减去 header 的大小。</p><p><strong>版本兼容</strong></p><p>注意到头部的 <code class="language-plaintext highlighter-rouge">version</code> 字段，它是用来保证客户端和服务端版本兼容的。Kafka保证的兼容策略是 <em>bidirectional compatibility</em>。即，新版本客户端可以访问旧版本的 broker；新版本 broker 可以接受旧版本的客户端的请求。</p><p>客户端在连接上 Broker 并实际开始工作之前，可以先发送 <code class="language-plaintext highlighter-rouge">ApiVersionsRequest</code> 请求到每个 Broker，以查询 Broker 支持的 版本列表，并从中选取一个它能识别的最高版本作为后续使用版本。</p><p>并且这个版本协商是基于连接的：每次连接断开并重连时，都要重新进行版本协商。因为断线可能正是因为Broker升级导致的。</p><h4 id="response"><span class="mr-2">Response</span><a href="#response" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h4></h4><p>每个回包也有固定的 <em>header</em>，具体格式如下：</p><div class="language-cpp highlighter-rouge"><div class="code-header"> <span data-label-text="Cpp"><i class="fas fa-code small"></i></span> <button aria-label="copy" data-title-succeed="已复制！"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
</pre><td class="rouge-code"><pre><span class="k">struct</span> <span class="nc">ResponseHeader</span>
<span class="p">{</span>
    <span class="kt">int32_t</span> <span class="n">size</span><span class="p">;</span>
    <span class="kt">int32_t</span> <span class="n">correlationId</span><span class="p">;</span>
<span class="p">};</span>
</pre></table></code></div></div><p>回包的 header 就很简单了，只有一个 <em>correlationId</em>。所以客户端必须要把处理回包时要用到的信息全部在发出请求时保存在请求上下文中，然后通过 <em>correlationId</em> 找到上下文。</p><h3 id="c实现"><span class="mr-2">C++实现</span><a href="#c实现" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3></h3><p>根据官方文档中的编解码规范，我们就可以自己写一个<a href="https://github.com/bookxiao/kafkaprotocpp">C++版本的编解码实现</a>了。</p><p>kafkaprotocpp的关键类有：</p><ul><li><code class="language-plaintext highlighter-rouge">Pack</code> &amp; <code class="language-plaintext highlighter-rouge">Unpack</code>。负责各种Kafka支持的数据类型的编解码；<li><code class="language-plaintext highlighter-rouge">Request</code>。负责 Request 的编解码；<li><code class="language-plaintext highlighter-rouge">Response</code>。负责 Response 的编解码；<li><code class="language-plaintext highlighter-rouge">Marshallable</code>。所有具体的请求或响应，都需要继承此抽象基类，实现自己的 <code class="language-plaintext highlighter-rouge">marshal</code>/<code class="language-plaintext highlighter-rouge">unmarshal</code>方法。</ul><p>以<code class="language-plaintext highlighter-rouge">MetadataRequest</code>为例，请求协议定义如下：</p><div class="language-cpp highlighter-rouge"><div class="code-header"> <span data-label-text="Cpp"><i class="fas fa-code small"></i></span> <button aria-label="copy" data-title-succeed="已复制！"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
</pre><td class="rouge-code"><pre><span class="k">struct</span> <span class="nc">MetadataRequest</span> <span class="o">:</span> <span class="k">public</span> <span class="n">Marshallable</span>
<span class="p">{</span>
    <span class="k">enum</span> <span class="p">{</span> <span class="n">apikey</span> <span class="o">=</span> <span class="n">ApiConstants</span><span class="o">::</span><span class="n">METADATA_REQUEST_KEY</span><span class="p">,</span> <span class="n">apiver</span> <span class="o">=</span> <span class="n">ApiConstants</span><span class="o">::</span><span class="n">API_VERSION0</span><span class="p">};</span>

    <span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">std</span><span class="o">::</span><span class="n">string</span><span class="o">&gt;</span> <span class="n">vecTopic</span><span class="p">;</span>

    <span class="k">virtual</span> <span class="kt">void</span> <span class="n">marshal</span><span class="p">(</span><span class="n">Pack</span> <span class="o">&amp;</span><span class="n">pk</span><span class="p">)</span> <span class="k">const</span>
    <span class="p">{</span>
        <span class="n">pk</span> <span class="o">&lt;&lt;</span> <span class="n">vecTopic</span><span class="p">;</span>
    <span class="p">}</span>
    <span class="k">virtual</span> <span class="kt">void</span> <span class="n">unmarshal</span><span class="p">(</span><span class="k">const</span> <span class="n">Unpack</span> <span class="o">&amp;</span><span class="n">up</span><span class="p">)</span>
    <span class="p">{</span>
        <span class="n">up</span> <span class="o">&gt;&gt;</span> <span class="n">vecTopic</span><span class="p">;</span>
    <span class="p">}</span>

<span class="p">};</span>

<span class="k">struct</span> <span class="nc">MetadataResponse</span> <span class="o">:</span> <span class="k">public</span> <span class="n">Marshallable</span>
<span class="p">{</span>
    <span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">Broker</span><span class="o">&gt;</span> <span class="n">vecBroker</span><span class="p">;</span>
    <span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">TopicMetadata</span><span class="o">&gt;</span> <span class="n">vecTopicMeta</span><span class="p">;</span>

    <span class="k">virtual</span> <span class="kt">void</span> <span class="n">marshal</span><span class="p">(</span><span class="n">Pack</span> <span class="o">&amp;</span><span class="n">pk</span><span class="p">)</span> <span class="k">const</span>
    <span class="p">{</span>
        <span class="n">pk</span> <span class="o">&lt;&lt;</span> <span class="n">vecBroker</span> <span class="o">&lt;&lt;</span> <span class="n">vecTopicMeta</span><span class="p">;</span>
    <span class="p">}</span>

    <span class="k">virtual</span> <span class="kt">void</span> <span class="n">unmarshal</span><span class="p">(</span><span class="k">const</span> <span class="n">Unpack</span> <span class="o">&amp;</span><span class="n">up</span><span class="p">)</span>
    <span class="p">{</span>
        <span class="n">up</span> <span class="o">&gt;&gt;</span> <span class="n">vecBroker</span> <span class="o">&gt;&gt;</span> <span class="n">vecTopicMeta</span><span class="p">;</span>
    <span class="p">}</span>
<span class="p">};</span>
</pre></table></code></div></div><p>收发请求如下：</p><div class="language-cpp highlighter-rouge"><div class="code-header"> <span data-label-text="Cpp"><i class="fas fa-code small"></i></span> <button aria-label="copy" data-title-succeed="已复制！"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
</pre><td class="rouge-code"><pre><span class="n">std</span><span class="o">::</span><span class="n">string</span> <span class="n">topic</span> <span class="o">=</span> <span class="s">"test"</span><span class="p">;</span>

<span class="n">MetadataRequest</span> <span class="n">metareq</span><span class="p">;</span>
<span class="n">metareq</span><span class="p">.</span><span class="n">vecTopic</span><span class="p">.</span><span class="n">push_back</span><span class="p">(</span><span class="n">topic</span><span class="p">);</span>
<span class="n">Request</span> <span class="nf">req</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="s">"meta_test"</span><span class="p">,</span> <span class="n">metareq</span><span class="p">.</span><span class="n">apikey</span><span class="p">,</span> <span class="n">metareq</span><span class="p">.</span><span class="n">apiver</span><span class="p">,</span> <span class="n">metareq</span><span class="p">);</span>

<span class="c1">// 发包到指定套接口</span>
<span class="kt">int</span> <span class="n">ret</span> <span class="o">=</span> <span class="n">send_request</span><span class="p">(</span><span class="n">sockfd</span><span class="p">,</span> <span class="n">req</span><span class="p">.</span><span class="n">data</span><span class="p">(),</span> <span class="n">req</span><span class="p">.</span><span class="n">size</span><span class="p">());</span>

<span class="c1">// 收包</span>
<span class="kt">char</span><span class="o">*</span> <span class="n">buf</span> <span class="o">=</span> <span class="n">read_response</span><span class="p">(</span><span class="n">sockfd</span><span class="p">);</span>
<span class="kt">size_t</span> <span class="n">len</span> <span class="o">=</span> <span class="n">Response</span><span class="o">::</span><span class="n">peeklen</span><span class="p">(</span><span class="n">buf</span><span class="p">);</span>
<span class="n">Response</span> <span class="nf">resp</span><span class="p">(</span><span class="n">buf</span><span class="p">,</span> <span class="n">len</span><span class="p">);</span>
<span class="n">resp</span><span class="p">.</span><span class="n">head</span><span class="p">();</span>
<span class="n">MetadataResponse</span> <span class="n">meta</span><span class="p">;</span>
<span class="k">try</span> <span class="p">{</span>
	<span class="n">meta</span><span class="p">.</span><span class="n">unmarshall</span><span class="p">(</span><span class="n">resp</span><span class="p">.</span><span class="n">up</span><span class="p">);</span>
<span class="p">}</span> <span class="k">catch</span><span class="p">(</span><span class="n">PacketError</span><span class="o">&amp;</span> <span class="n">pe</span><span class="p">)</span> <span class="p">{</span>
<span class="p">}</span>
<span class="c1">// 处理Meta信息</span>
</pre></table></code></div></div><p>感兴趣的可以具体去我的github看它的源码。</p><h2 id="2-partition存储模型"><span class="mr-2">2 Partition存储模型</span><a href="#2-partition存储模型" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2></h2><p>在深入了解 Producer 和 Consumer 的交互流程之前，我们先来看下Kafka的存储模型。</p><p>在 Kafka 中，<em>topic</em> 是消息的逻辑单元：不同的 topic 代表了不同的业务数据，是完全相互独立的。<em>partition</em> 则是消息存储的物理单元：每个 topic 可以分成若干个 partition，不同的 partition 可以存储在不同的 Broker 上。</p><p>我们先来看下如何在 Kafka 中创建 topic：</p><div class="language-sh highlighter-rouge"><div class="code-header"> <span data-label-text="Shell"><i class="fas fa-code small"></i></span> <button aria-label="copy" data-title-succeed="已复制！"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
</pre><td class="rouge-code"><pre><span class="nv">$ </span>bin/kafka-topics.sh <span class="nt">--create</span> <span class="nt">--zookeeper</span> localhost:2181 <span class="nt">--replication-factor</span> 2 <span class="nt">--partitions</span> 3 <span class="nt">--topic</span> <span class="nb">test</span>
</pre></table></code></div></div><p>这里我们指定了3个参数：</p><ul><li><code class="language-plaintext highlighter-rouge">--topic</code>表示名称，必须唯一；<li><code class="language-plaintext highlighter-rouge">--partitions</code>表示分区个数，据消息并发吞吐量和客户端处理能力设置；<li><code class="language-plaintext highlighter-rouge">--replication-factor</code>表示消息备份数，决定了数据的可靠性</ul><p>接下来可以看到这个topic的具体分区信息：</p><div class="language-sh highlighter-rouge"><div class="code-header"> <span data-label-text="Shell"><i class="fas fa-code small"></i></span> <button aria-label="copy" data-title-succeed="已复制！"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
</pre><td class="rouge-code"><pre><span class="nv">$ </span>kafka/bin/kafka-topics.sh <span class="nt">--zookeeper</span> localhost:2181 <span class="nt">--describe</span> <span class="nt">--topic</span> <span class="nb">test
</span>Topic:test PartitionCount:3	ReplicationFactor:2	Configs:
	Topic: <span class="nb">test </span>Partition: 0	Leader: 402	Replicas: 402,401	Isr: 402,401
	Topic: <span class="nb">test	</span>Partition: 1	Leader: 403	Replicas: 403,402	Isr: 403,402
	Topic: <span class="nb">test	</span>Partition: 2	Leader: 401	Replicas: 401,403	Isr: 401,403
</pre></table></code></div></div><p>当我们在创建topic的时候，kafka会创建指定数量的partition，并将其存储在若干个（由<code class="language-plaintext highlighter-rouge">ReplicationFactor</code>决定）Broker上。</p><p>在这些Broker中，会选出一个作为这个 partition 的 leader，来负责它的生产和消费请求。</p><blockquote><p>在Kafka集群中，会有一个Broker被选举为集群的 <em>Controller</em> （借助Zookeeper），来负责partition的分配工作，重点是保证集群内各Broker的负载均衡。</p></blockquote><p>例如，这里 <code class="language-plaintext highlighter-rouge">Partition 0</code> 落在了 <em>402,401</em> 这两个Broker上，并且其中排在前面的那个就是它的 Leader。当我们要发布或消费这个 partition 的消息时，必须将 <code class="language-plaintext highlighter-rouge">Producer &amp; Fetch</code>请求发到这台 Broker。</p><h2 id="3-producer-工作流程"><span class="mr-2">3 Producer 工作流程</span><a href="#3-producer-工作流程" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2></h2><p>接下来看下 Producer 发布消息到 Kafka 时的流程，看看中间都经历了些什么：</p><p><img data-src="https://raw.githubusercontent.com/bookxiao/picsbed/main/kafka/kafka_producer.png" alt="ProducerSeq" data-proofer-ignore></p><p>这里，我们假定集群有2台Broker，每台Broker各自是一个partition的leader。那么Producer的具体流程可以描述为：</p><ol><li>Producer向 <em>BootstrapServer</em> 发送 <code class="language-plaintext highlighter-rouge">MetadataRequest</code>，查询集群当前Broker列表，以及partition的leader信息；<li>Producer向 Broker1 请求发布消息到 <em>partition-0</em>，收到成功回复；<li>Kafka集群发生 leader 转移，<em>partition-0</em> 的 leader 变成了 Broker2；<li>Producer再次向 Broker1 发布消息，收到错误码（<em>UNKNOWN_TOPIC_OR_PARTITION</em>）；<li>Producer再次向任意一台 Broker 发送 <code class="language-plaintext highlighter-rouge">MetadataRequest</code>，查询最新的 leader 信息；<li>Producer重新向 Broker2 请求发布消息到 <em>partition-0</em>，收到成功回复。</ol><p>可以看到，整个发布流程只涉及到两个协议：<code class="language-plaintext highlighter-rouge">MetadataRequest</code> 和 <code class="language-plaintext highlighter-rouge">ProduceRequest</code>。</p><h3 id="metadatarequest"><span class="mr-2">MetadataRequest</span><a href="#metadatarequest" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3></h3><p>官方格式定义：</p><div class="language-sh highlighter-rouge"><div class="code-header"> <span data-label-text="Shell"><i class="fas fa-code small"></i></span> <button aria-label="copy" data-title-succeed="已复制！"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
</pre><td class="rouge-code"><pre>Metadata Request <span class="o">(</span>Version: 0<span class="o">)</span> <span class="o">=&gt;</span> <span class="o">[</span>topics]
  topics <span class="o">=&gt;</span> name
	name <span class="o">=&gt;</span> STRING

Metadata Response <span class="o">(</span>Version: 0<span class="o">)</span> <span class="o">=&gt;</span> <span class="o">[</span>brokers] <span class="o">[</span>topics] 
  brokers <span class="o">=&gt;</span> node_id host port 
    node_id <span class="o">=&gt;</span> INT32
    host <span class="o">=&gt;</span> STRING
    port <span class="o">=&gt;</span> INT32
  topics <span class="o">=&gt;</span> error_code name <span class="o">[</span>partitions] 
    error_code <span class="o">=&gt;</span> INT16
    name <span class="o">=&gt;</span> STRING
    partitions <span class="o">=&gt;</span> error_code partition_index leader_id <span class="o">[</span>replica_nodes] <span class="o">[</span>isr_nodes] 
      error_code <span class="o">=&gt;</span> INT16
      partition_index <span class="o">=&gt;</span> INT32
      leader_id <span class="o">=&gt;</span> INT32
      replica_nodes <span class="o">=&gt;</span> INT32
      isr_nodes <span class="o">=&gt;</span> INT32
</pre></table></code></div></div><p><code class="language-plaintext highlighter-rouge">Metadata</code>主要查询两种信息：</p><ul><li>集群的Broker列表，包括 <em>node_id, host, port</em> 等信息；<li>指定的topic信息，包括 partition 数量，以及每个 partition 的 <em>leader, replicas, isrs</em>等。</ul><p>如果查询时没有指定任何 topic，那么会查询到集群所有的 topic 信息。</p><p>Kafka Client 有两种场景下会发送<code class="language-plaintext highlighter-rouge">MetadataRequest</code>：</p><ul><li>启动之后定期查询，以便感知到新的Broker信息和topic信息（例如partition扩容了）；<li>当生产或消费时，提示当前Broker已经不是Leader了，需要及时更新信息</ul><p>正是因为有<code class="language-plaintext highlighter-rouge">Metadata</code>协议的存在，Kafka Client在运行过程中总是能动态感知到集群所有的Broker信息。因此，我们在启动 Producer 或 Consumer 时，配置的<code class="language-plaintext highlighter-rouge">bootstrap.server</code>只需要包含一台可用的Broker信息就可以了。</p><p>此外，我们通过<code class="language-plaintext highlighter-rouge">MetadataResponse</code>获取到的 Broker 的 <em>host</em> 就是我们在部署 Kafka 时配置的<code class="language-plaintext highlighter-rouge">advertised.listeners</code>项。需要注意它和<code class="language-plaintext highlighter-rouge">listeners</code>的区别：</p><ul><li><code class="language-plaintext highlighter-rouge">listeners</code>配置的是 Kafka 监听的套接口，例如我们可以配置为<code class="language-plaintext highlighter-rouge">PLAINTEXT://0.0.0.0:9092</code>来监听本机所有网口；<li><code class="language-plaintext highlighter-rouge">advertised.listeners</code>是写入到ZooKeeper进而被客户端通过<code class="language-plaintext highlighter-rouge">MetadataRequest</code>拿到的地址</ul><p>举个例子，假定我们的Kafka部署在双线或多线机房，为了保证高可用，我们通常是配置为监听所有网口。但是<code class="language-plaintext highlighter-rouge">advertised.listeners</code>又不能配置为0，所以我们可以给它配置成一个域名：这个域名再绑定Broker的所有网口的具体IP。这样KafkaClient拿到域名后就可以解析到多个IP，并在连接断开时可以尝试使用另外的IP来重连。</p><h3 id="producerequest"><span class="mr-2">ProduceRequest</span><a href="#producerequest" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3></h3><p>官方协议定义：</p><div class="language-sh highlighter-rouge"><div class="code-header"> <span data-label-text="Shell"><i class="fas fa-code small"></i></span> <button aria-label="copy" data-title-succeed="已复制！"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
</pre><td class="rouge-code"><pre>v0, v1 <span class="o">(</span>supported <span class="k">in </span>0.9.0 or later<span class="o">)</span> and v2 <span class="o">(</span>supported <span class="k">in </span>0.10.0 or later<span class="o">)</span>
ProduceRequest <span class="o">=&gt;</span> RequiredAcks Timeout <span class="o">[</span>TopicName <span class="o">[</span>Partition MessageSetSize MessageSet]]
  RequiredAcks <span class="o">=&gt;</span> int16
  Timeout <span class="o">=&gt;</span> int32
  Partition <span class="o">=&gt;</span> int32
  MessageSetSize <span class="o">=&gt;</span> int32

v2 <span class="o">(</span>supported <span class="k">in </span>0.10.0 or later<span class="o">)</span>
ProduceResponse <span class="o">=&gt;</span> <span class="o">[</span>TopicName <span class="o">[</span>Partition ErrorCode Offset Timestamp]] ThrottleTime
  TopicName <span class="o">=&gt;</span> string
  Partition <span class="o">=&gt;</span> int32
  ErrorCode <span class="o">=&gt;</span> int16
  Offset <span class="o">=&gt;</span> int64
  Timestamp <span class="o">=&gt;</span> int64
  ThrottleTime <span class="o">=&gt;</span> int32
</pre></table></code></div></div><p>从协议可以看出来，这是一个批量接口：每次请求可以指定发数据给多个 topic 或者多个 partition 。</p><p>这里重点看一下 <code class="language-plaintext highlighter-rouge">RequireAcks</code> 参数，它决定了生产者往Kafka发消息的可靠性。它表示的意思是：Leader 收到请求后需要等待多少个 replicas 的 ack，才能回包给客户端。它的取值为：</p><ul><li>0，表示Leader不会发送回包给客户端；<li>大于0且小于 ReplicaFactor 的整数，表示将数据同步到指定数量的 Broker 上才给客户端回包；<li>-1，表示Leader会将数据同步到所有 ISR 集合中的Broker后才给客户端回包。</ul><p>所以，<code class="language-plaintext highlighter-rouge">RequireAcks</code>值越大，表示可靠性越高，但是效率就相应地越低了。不过要更详细地描述可靠性的话，还得理解一个概念 <em>ISR</em>。</p><p>在Kafka内部，Leader 和 Follower 间的数据同步，依靠每个 Follower 通过 <em>long-pull</em> 模式一直不停地从 Leader 拉取数据。那自然地，Leader 会维护每个 Follower 拉取到了哪个 offset，以及与最新offset的差值是多少。当这个差值（lag值）不超过某个既定值时，就认为这个 Follower 是跟 Leader 保持同步的，属于 <em>In-Sync-Replicas</em> 集合。</p><p>显然，这个 ISR 集合是动态变化的。当某个 Follower 长时间没有过来拉，或者 lag 值比较大时，就会被踢出 ISR；当它恢复之后，又会被重新加入 ISR 集合。只有被 ISR 集合中所有的 Broker 都同步的消息，才被认为是已提交的（<em>committed</em>）。只有已提交的消息，才能被消费者看到。</p><p>如果当前 leader 挂了，因为已提交的消息肯定在 ISR 集合中的其它 Broker 上都存在，所以只要ISR集合不为空，那么重新选一个作为 Leader 即可。但是如果 ISR 为空呢？这取决于另外一个参数 <code class="language-plaintext highlighter-rouge">unclean.leader.election.enable</code>：如果设置为 true，那么可以选择一个不在 ISR 集合中的 Replica 作为 leader。但是这可能导致部分已提交的消息丢了，相当于是拿 可靠性 换 可用性。</p><blockquote><p>此参数可全局设置，也可针对 topic 设置。</p></blockquote><p>再说回 ProduceRequet。假定我们有个 partition 的 ReplicaFactor 为3，表示会存储在 3 台 Broker（包括Leader）上。如果发布时的 <code class="language-plaintext highlighter-rouge">RequireAcks</code> 填了 3，那就表示每次发布都要 3 台都同步到数据才算成功。那如果 ISR 集合中没有 3 台会怎样呢？答案就是不可写。</p><p>从某种程度来说，我们在创建 topic 时指定的 <em>ReplicaFactor</em> 就已经表示了我们对这个 topic 的数据可靠性的要求了。那如果在发布时再去设置ack值，感觉有点冗余了。而且有时候我们在发布的时候，不太好知道这个topic的具体ReplicaFactor值。所以，我们可以将 acks 填为 -1，表示等待当前ISR集合中都同步了就算成功。</p><p>在一切正常的情况下，ISR 集合就等于 Replicas 集合；当出问题时，有问题的Broker就会被踢出 ISR 集合。考虑到在不出问题的时候，除Leader之外的Replicas是发挥不出作用的，所以如果没有其它机制保障的话，acks 填 -1，好像可靠性不太“稳定”。</p><p>所以 Kafka 提供了另外一个参数<code class="language-plaintext highlighter-rouge">min.insync.replicas</code>。当 acks 填 -1 时，如果 ISR 集合数量小于此值的话，拒绝写入数据。这样就给可靠性设置了一个底线。</p><blockquote><p>此参数可全局设置，也可针对 topic 设置。</p></blockquote><h2 id="4-consumer-工作流程"><span class="mr-2">4 Consumer 工作流程</span><a href="#4-consumer-工作流程" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2></h2><p>消费组的工作原理，其实可以分解成3个相互独立的子过程：</p><ul><li>组关系的维护。包括 <em>JoinGroup, SyncGroup, LeaveGroup</em> 以及维持组状态的心跳包 <em>HeartBeat</em>；<li>offset偏移量的管理。包括 <em>FetchOffset, FetchCgroupOffset, CommitOffset</em> 等；<li>拉取消息。包括 <em>FetchMessage</em> 等。</ul><p>这3个过程相互独立，从协议交互角度来说，你可以单独调用每个过程涉及到的协议来实现特定目的。</p><h3 id="维护消费组关系"><span class="mr-2">维护消费组关系</span><a href="#维护消费组关系" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3></h3><p><strong>关于Coordinator</strong></p><p>为了保证数据的一致性，每个消费组的状态都由某个固定的 Broker 来管理。这个 Broker 称为该消费组的 <em>Coordinator</em>。从负载均衡角度来讲，集群内每个Broker都是差不多数量的消费组的 Coordinator。针对特定消费组来说，它的所有的组管理相关的请求都必须发送给 Coordinator 才能被处理。</p><p>因此，Consumer 启动后的第一件事，就是查询它的 Coordinator。方法很简单，发送 <code class="language-plaintext highlighter-rouge">QueryCoordinator</code> 请求到任意一台 Broker 即可。</p><p><strong>关于消费组</strong></p><p>在一个消费组里，每个 Consumer 都会被 Coordinator 分配一个唯一的 <em>memberid</em>。并且，Coordinator会挑选一个 Consumer 作为这个消费组的 <em>leader</em>。</p><p>所谓消费组，就是多个消费者共同出力来消费某个（些）topic的所有parittion。所有的这些 partition 会被均衡地分配给所有的消费者。也因此，partition 数量一般不会超过消费者的数量。当然，如果只有1个parittion，为了保证高可用，也会起2个消费者，以便当其中1个出问题的时候，另1个能立即接管过来。</p><p>那谁来负责在组内分配 partition 呢？你可能会觉得是 Coordinator，但其实不是！真正负责分配的是消费组的 leader Consumer。这也是 Coordinator 的名字的由来：Broker 只是帮忙协调和维护组关系，具体涉及到消费的活（包括分配），都是由 Consumer 自己完成。</p><p><strong>关于消费组状态</strong></p><p>维护组关系，其本质就是在客户端中维护一个消费组的状态机，如下图所示：</p><p><img data-src="https://raw.githubusercontent.com/bookxiao/picsbed/main/kafka/cgroup_fsm.png" alt="cgroup_fsm" data-proofer-ignore></p><p>在描述状态机转移过程之前，我们先来看一下一个正常的消费组的状态：</p><p>每个成员都处于 <code class="language-plaintext highlighter-rouge">CS_UP</code> 状态，各自消费自己负责的 partition，并且需要每隔固定间隔（不超过配置值 <code class="language-plaintext highlighter-rouge">heartbeat.interval.ms</code>）发送心跳包给 <code class="language-plaintext highlighter-rouge">Coordinator</code> 来维持状态，否则就会被踢出消费组。</p><p>好了，再来看 Consumer 的状态机转移过程：</p><ul><li>消费者启动后默认是<code class="language-plaintext highlighter-rouge">CS_DOWN</code>状态，然后发送<code class="language-plaintext highlighter-rouge">JoinGroup</code>给 Coordinator 来请求加入组，并转变为<code class="language-plaintext highlighter-rouge">CS_JOINING</code>状态；<li>当 Coordinator 察觉到成员有变动时，它会在每个现有成员的下一个心跳包回包中告知它们，需要重新发起<code class="language-plaintext highlighter-rouge">JoinGroup</code>。这样，每个现有成员就从 <code class="language-plaintext highlighter-rouge">CS_UP</code>状态变为<code class="language-plaintext highlighter-rouge">CS_JOINING</code>；<li>当 Coordinator 收到所有成员的 Join 请求后，就会从中选出新的 leader，并且通过 JoinResponse 告知所有成员谁是 leader。其中，给 leader 的回包中，会带上所有成员的信息以及它们订阅的topic列表；<li>当消费者收到 JoinResponse 后，就会知道自己是不是 leader。如果是 leader，就需要分配 partition 了，然后把分配结果放在 <code class="language-plaintext highlighter-rouge">SyncGroup</code> 中发送给 Coordinator。除了 leader 之外，其它成员也都需要发送 <code class="language-plaintext highlighter-rouge">SyncGroup</code>，只不过不用带分配结果。这样，所有成员都从 <code class="language-plaintext highlighter-rouge">CS_JOINING</code> 变成了 <code class="language-plaintext highlighter-rouge">CS_SYNCING</code>；<li>Coordinator 收到所有成员的 SyncGroup 请求后，会将 leader 上传的分配结果放到 <code class="language-plaintext highlighter-rouge">SyncResponse</code> 告知给所有成员。这样所有成员收到回包后，就知道自己该负责消费哪些 partition 了，然后状态从 <code class="language-plaintext highlighter-rouge">CS_SYNCING</code> 变成 <code class="language-plaintext highlighter-rouge">CS_UP</code>，就可以准备干活了。<li>此后，每个成员要继续定期发送 <code class="language-plaintext highlighter-rouge">Heartbeat</code> 以保持在 <code class="language-plaintext highlighter-rouge">CS_UP</code> 状态。</ul><p>以上就是整个消费组的状态转移过程了。为了避免一些非法的消费者进程（例如那些卡了很久然后突然又恢复了）干扰消费组状态，Coordinator 会为每个消费组维护一个单调递增的 <code class="language-plaintext highlighter-rouge">generationId</code>。每次有成员变动时，<code class="language-plaintext highlighter-rouge">generationId</code>都会加1。当收到<code class="language-plaintext highlighter-rouge">generationId</code>与当前值不一致的请求时，会拒绝。</p><p><strong>关于消费组偏移量</strong></p><p>当拿到分配结果后，Consumer 就准备开始干活了。</p><p>相比于单机版的消费模式，消费组除了能负载均衡之外，还有另外一个好处：Coordinator 可以帮助存储上次消费到的偏移量，以便当某个partition从一个消费者转移到另一个消费者时，可以接着消费，从而保证消息不丢失。</p><p>所以，Consumer 在具体拉取消息之前，要首先能够知道该从哪个位置开始拉取。方法也很简单，发送 <code class="language-plaintext highlighter-rouge">OffsetFetchRequest</code> 到 Coordinator 就可以获取到之前提交的便宜量了。</p><div class="language-sh highlighter-rouge"><div class="code-header"> <span data-label-text="Shell"><i class="fas fa-code small"></i></span> <button aria-label="copy" data-title-succeed="已复制！"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
</pre><td class="rouge-code"><pre>v0 and v1 <span class="o">(</span>supported <span class="k">in </span>0.8.2 or after<span class="o">)</span>:
OffsetFetchRequest <span class="o">=&gt;</span> ConsumerGroup <span class="o">[</span>TopicName <span class="o">[</span>Partition]]
  ConsumerGroup <span class="o">=&gt;</span> string
  TopicName <span class="o">=&gt;</span> string
  Partition <span class="o">=&gt;</span> int32

v0 and v1 <span class="o">(</span>supported <span class="k">in </span>0.8.2 or after<span class="o">)</span>:
OffsetFetchResponse <span class="o">=&gt;</span> <span class="o">[</span>TopicName <span class="o">[</span>Partition Offset Metadata ErrorCode]]
  TopicName <span class="o">=&gt;</span> string
  Partition <span class="o">=&gt;</span> int32
  Offset <span class="o">=&gt;</span> int64
  Metadata <span class="o">=&gt;</span> string
  ErrorCode <span class="o">=&gt;</span> int16
</pre></table></code></div></div><p>那如果这个消费组之前没人提交过对应 partition 的 offset 呢？</p><p>那就需要用另外一个协议了——发送 <code class="language-plaintext highlighter-rouge">OffsetRequest</code> 到 partition 的 Leader Broker。</p><div class="language-sh highlighter-rouge"><div class="code-header"> <span data-label-text="Shell"><i class="fas fa-code small"></i></span> <button aria-label="copy" data-title-succeed="已复制！"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
</pre><td class="rouge-code"><pre>// v0
ListOffsetRequest <span class="o">=&gt;</span> ReplicaId <span class="o">[</span>TopicName <span class="o">[</span>Partition Time MaxNumberOfOffsets]]
  ReplicaId <span class="o">=&gt;</span> int32
  TopicName <span class="o">=&gt;</span> string
  Partition <span class="o">=&gt;</span> int32
  Time <span class="o">=&gt;</span> int64
  MaxNumberOfOffsets <span class="o">=&gt;</span> int32
           
             
// v1 <span class="o">(</span>supported <span class="k">in </span>0.10.1.0 and later<span class="o">)</span>
ListOffsetRequest <span class="o">=&gt;</span> ReplicaId <span class="o">[</span>TopicName <span class="o">[</span>Partition Time]]
  ReplicaId <span class="o">=&gt;</span> int32
  TopicName <span class="o">=&gt;</span> string
  Partition <span class="o">=&gt;</span> int32
  Time <span class="o">=&gt;</span> int64
</pre></table></code></div></div><p>这个请求可以查询到指定 partitions 的偏移量信息。其中，参数 <code class="language-plaintext highlighter-rouge">Time</code> 可以指定要查询哪个时间戳的便宜量，取值可以为：</p><ul><li><code class="language-plaintext highlighter-rouge">&gt; 0</code>。表示查询指定时间戳（单位ms）之前的最后一条消息的offset；<li><code class="language-plaintext highlighter-rouge">-1</code>。表示查询最近的offset（<em>latest</em>）；<li><code class="language-plaintext highlighter-rouge">-2</code>。表示查询最老的offset（<em>earlist</em>）。</ul><p>这也是我们在配置 Consumer 时经常碰到的一个参数：<code class="language-plaintext highlighter-rouge">auto.offset.reset</code>。只不过比较奇怪的是，明明协议层面可以支持配置一个具体的时间戳，但是所有的Client暴露出来的接口，只能配置成 <em>earliest</em> 或 <em>latest</em>。</p><p>当消费组正常消费时，可以随时把已经消费过的偏移量提交到 Coordinator。方法就是发送 <code class="language-plaintext highlighter-rouge">OffsetCommitRequest</code> 到 Coordinator。</p><p>提交到 Coordinator 的offset信息也是有个有效期的，当超过规定时候没有提交时，Broker 也会把 offset 给删掉的。这样也会重新触发上面提到的没有初始偏移量的逻辑。</p><p>这里有个点，就是 Coordinator 不会去校验你提交的offset是否合法。换句话说，它只是提供了一个 key 为 <code class="language-plaintext highlighter-rouge">'groupid/topic/partition'</code>，value 为 int64 的读写接口。</p><blockquote><p>我们可以利用这个特点，来为Kafka跨集群做数据同步。Kafka跨集群同步，方法一般就是在源机房部署一套消费者，然后将消息发布到目的机房。</p><p>那这里就涉及到是采用 同机房消费，跨机房发布 还是 跨机房消费，同机房发布 的选择了。</p><ul><li>跨机房消费，意味着消费组的状态不稳定，频繁的网络超时会导致消费组的 rebalance。在消费组 rebalance 时，所有消费都需要暂停。但是跨机房拉取消息本身没有副作用；<li>跨机房发布，意味着当网络超时时，发布端需要重发，导致目的机房消息重复。(不过新版本Kafka已经支持发布端逻辑去重了)</ul><p>不过借助上面提到的特点，我们可以在目的机房部署消费组，但是把消费组的组管理和offset管理放在目的机房Kafka（即在目的机房加入消费组），但是提交的offset其实是源机房partition的offset， 消息还是从源机房拉取。</p><p>这样就综合了两种方案的优点，并且规避了各自的缺点。不过这种方案需要定制化Kafka的SDK。</p></blockquote><p><strong>关于拉取消息</strong></p><p>有了 partition 列表，有了每个 partition 的初始offset，那么接下来 Consumer 的工作就很简单了，只要通过 <em>long-pull</em> 模式不停地去各自 partition 的leader 拉取消息即可。</p><p>拉取消息通过发送 <code class="language-plaintext highlighter-rouge">FetchRequest</code> 给 leader：</p><div class="language-sh highlighter-rouge"><div class="code-header"> <span data-label-text="Shell"><i class="fas fa-code small"></i></span> <button aria-label="copy" data-title-succeed="已复制！"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
</pre><td class="rouge-code"><pre>FetchRequest <span class="o">=&gt;</span> ReplicaId MaxWaitTime MinBytes <span class="o">[</span>TopicName <span class="o">[</span>Partition FetchOffset MaxBytes]]
  ReplicaId <span class="o">=&gt;</span> int32
  MaxWaitTime <span class="o">=&gt;</span> int32
  MinBytes <span class="o">=&gt;</span> int32
  TopicName <span class="o">=&gt;</span> string
  Partition <span class="o">=&gt;</span> int32
  FetchOffset <span class="o">=&gt;</span> int64
  MaxBytes <span class="o">=&gt;</span> int32

v1 <span class="o">(</span>supported <span class="k">in </span>0.9.0 or later<span class="o">)</span> and v2 <span class="o">(</span>supported <span class="k">in </span>0.10.0 or later<span class="o">)</span>
FetchResponse <span class="o">=&gt;</span> ThrottleTime <span class="o">[</span>TopicName <span class="o">[</span>Partition ErrorCode HighwaterMarkOffset MessageSetSize MessageSet]]
  ThrottleTime <span class="o">=&gt;</span> int32
  TopicName <span class="o">=&gt;</span> string
  Partition <span class="o">=&gt;</span> int32
  ErrorCode <span class="o">=&gt;</span> int16
  HighwaterMarkOffset <span class="o">=&gt;</span> int64
  MessageSetSize <span class="o">=&gt;</span> int32
</pre></table></code></div></div><p>在拉取时，可以指定 <code class="language-plaintext highlighter-rouge">MinBytes</code> 和 <code class="language-plaintext highlighter-rouge">MaxBytes</code>，来指定本次拉取最少和最多拉取多少数据，以及最多等待时间 <code class="language-plaintext highlighter-rouge">MaxWaitTime</code>。在回包中，Kafka除了返回具体的消息之外，还会返回一个参数<code class="language-plaintext highlighter-rouge">HighwaterMarkOffset</code>，表示该 partition 目前可供消费者消费的最新的offset。通过此值我们可以知道还有多少消息待拉取。</p><p>这里需要注意的是，<code class="language-plaintext highlighter-rouge">HighwaterMarkOffset</code>表示的是消费者能看到的最新offset，不表示发布者最新发布的offset。这个涉及到Kafka内部同步机制，只有被所有 ISR 集合中的Broker同步的消息，才能增加 <code class="language-plaintext highlighter-rouge">HighwaterMarkOffset</code>。</p><h2 id="5-总结"><span class="mr-2">5 总结</span><a href="#5-总结" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2></h2><p>除了 Producer 和 Consumer 相关协议之外，Kafka还提供一些管理类的API，包括 <code class="language-plaintext highlighter-rouge">ListGroup</code>（列出所有消费组）、<code class="language-plaintext highlighter-rouge">DescribeGroups</code>（查询消费组状态）等等。新版kafka还提供了创建Topic之类的APi。深度利用这些协议可以用来写一些Kafka的监控管理插件。</p><p>弄懂Kafka的协议交互流程，除了可以加深对Kafka的理解之外，还有以下的好处：</p><ul><li>帮助定位生产者和消费者的问题。由于Kafka Broker不会打印任何与客户端相关的异常日志信息，全部都是以错误码的形式告知给客户端。因此了解协议交互流程，就可以更好地从客户端侧的日志了解到具体是哪个环节出问题；<li>实现自己的KafkaSdk。由于作者在工作中需要实现Kafka的跨集群同步数据，而开源的sdk都不太适合，因此只能自己实现了一个C++版sdk；<li>兼容Kafka协议来提供服务。Kafka已经在互联网行业得到大规模应用，如果新开发的MQ系统可以兼容Kafka协议，那么可以掠夺大量的Kafka使用者，实现无缝迁移。例如最近比较火热的 <a href="https://pulsar.apache.org/">pulsar</a>，就是通过 <a href="https://github.com/streamnative/kop">Kop</a> 插件来兼容了Kafka协议。</ul><p>希望本篇文章可以让大家更加理解Kafka的工作模式。</p></div><div class="post-tail-wrapper text-muted"><div class="post-meta mb-3"> <i class="far fa-folder-open fa-fw mr-1"></i> <a href='/categories/kafka/'>kafka</a></div><div class="post-tags"> <i class="fa fa-tags fa-fw mr-1"></i> <a href="/tags/kafka/" class="post-tag no-text-decoration" >kafka</a></div><div class="post-tail-bottom d-flex justify-content-between align-items-center mt-3 pt-5 pb-2"><div class="license-wrapper"> 本文由作者按照 <a href="https://creativecommons.org/licenses/by/4.0/"> CC BY 4.0 </a> 进行授权</div><div class="share-wrapper"> <span class="share-label text-muted mr-1">分享</span> <span class="share-icons"> <a href="https://twitter.com/intent/tweet?text=Kafka原理学习之协议交互流程 - 王书孝&amp;url=/posts/kafka-protocol/" data-toggle="tooltip" data-placement="top" title="Twitter" target="_blank" rel="noopener" aria-label="Twitter"> <i class="fa-fw fab fa-twitter"></i> </a> <a href="https://www.facebook.com/sharer/sharer.php?title=Kafka原理学习之协议交互流程 - 王书孝&amp;u=/posts/kafka-protocol/" data-toggle="tooltip" data-placement="top" title="Facebook" target="_blank" rel="noopener" aria-label="Facebook"> <i class="fa-fw fab fa-facebook-square"></i> </a> <a href="https://t.me/share/url?url=/posts/kafka-protocol/&amp;text=Kafka原理学习之协议交互流程 - 王书孝" data-toggle="tooltip" data-placement="top" title="Telegram" target="_blank" rel="noopener" aria-label="Telegram"> <i class="fa-fw fab fa-telegram"></i> </a> <i id="copy-link" class="fa-fw fas fa-link small" data-toggle="tooltip" data-placement="top" title="分享链接" data-title-succeed="链接已复制！"> </i> </span></div></div></div></div></div><div id="panel-wrapper" class="col-xl-3 pl-2 text-muted"><div class="access"><div id="access-tags"><div class="panel-heading">热门标签</div><div class="d-flex flex-wrap mt-3 mb-1 mr-3"> <a class="post-tag" href="/tags/kafka/">kafka</a> <a class="post-tag" href="/tags/golang/">golang</a> <a class="post-tag" href="/tags/io-copy/">io.Copy</a> <a class="post-tag" href="/tags/ioutil-readall/">ioutil.ReadAll</a></div></div></div><script src="https://cdn.jsdelivr.net/gh/afeld/bootstrap-toc@1.0.1/dist/bootstrap-toc.min.js"></script><div id="toc-wrapper" class="pl-0 pr-4 mb-5"><div class="panel-heading pl-3 pt-2 mb-2">文章内容</div><nav id="toc" data-toggle="toc"></nav></div></div></div><div class="row"><div class="col-12 col-lg-11 col-xl-8"><div id="tail-wrapper" class="pl-1 pr-1 pl-sm-2 pr-sm-2 pl-md-4 pr-md-4"><div id="related-posts" class="mt-5 mb-2 mb-sm-4"><h3 class="pt-2 mt-1 mb-4 ml-1" data-toc-skip>相关文章</h3><div class="card-deck mb-4"><div class="card"> <a href="/posts/learning-kafka-message-timestamps/"><div class="card-body"> <em class="timeago small" data-ts="1612263600" > 2021-02-02 </em><h3 class="pt-0 mt-1 mb-3" data-toc-skip>Kafka原理学习之消息时间戳</h3><div class="text-muted small"><p> 本文主要讲述kafka对消息时间戳提供的一些支持，以及kafka如何支持根据时间戳精确查找offset。 1 前言 得益于kafka良好的设计理念，Producer和Consumer完全独立，互不影响，各司其职即可。但是，对于消费者而言，当它从kafka拿到一条消息时，它可能会想知道，这条消息是何时发布到kafka的呢? 另外，当消费者开始消费时，除了从最新的offset或最久的off...</p></div></div></a></div><div class="card"> <a href="/posts/golang-iocopy/"><div class="card-body"> <em class="timeago small" data-ts="1612429200" > 2021-02-04 </em><h3 class="pt-0 mt-1 mb-3" data-toc-skip>golang中的io.Copy 和 ioutil.ReadAll</h3><div class="text-muted small"><p> golang中当我们需要拷贝数据时，常常用到 io.Copy 和 ioutil.ReadAll。那么这两个函数有什么区别，以及在何时应该用哪个呢？ ioutil.ReadAll 之所以把ReadAll单独拿出来讲，一来是因为我们经常需要把数据从某个 io.Reader对象读出来，二来也是因为它的性能问题常常被人吐槽。 先来看下它的使用场景。比如说，我们使用http.Client发送GE...</p></div></div></a></div></div></div><div class="post-navigation d-flex justify-content-between"> <a href="/posts/learning-kafka-message-timestamps/" class="btn btn-outline-primary" prompt="上一篇"><p>Kafka原理学习之消息时间戳</p></a> <a href="/posts/golang-iocopy/" class="btn btn-outline-primary" prompt="下一篇"><p>golang中的io.Copy 和 ioutil.ReadAll</p></a></div></div></div></div><footer class="d-flex w-100 justify-content-center"><div class="d-flex justify-content-between align-items-center text-muted"><div class="footer-left"><p class="mb-0"> © 2022 <a href="https://github.com/bookxiao">王书孝</a>. <span data-toggle="tooltip" data-placement="top" title="除非另有说明，本网站上的博客文章均由作者按照知识共享署名 4.0 国际 (CC BY 4.0) 许可协议进行授权。">保留部分权利。</span></p></div><div class="footer-right"><p class="mb-0"> 本站由 <a href="https://jekyllrb.com" target="_blank" rel="noopener">Jekyll</a> 生成，采用 <a href="https://github.com/cotes2020/jekyll-theme-chirpy" target="_blank" rel="noopener">Chirpy</a> 主题。</p></div></div></footer></div><div id="search-result-wrapper" class="d-flex justify-content-center unloaded"><div class="col-12 col-sm-11 post-content"><div id="search-hints"><div id="access-tags"><div class="panel-heading">热门标签</div><div class="d-flex flex-wrap mt-3 mb-1 mr-3"> <a class="post-tag" href="/tags/kafka/">kafka</a> <a class="post-tag" href="/tags/golang/">golang</a> <a class="post-tag" href="/tags/io-copy/">io.Copy</a> <a class="post-tag" href="/tags/ioutil-readall/">ioutil.ReadAll</a></div></div></div><div id="search-results" class="d-flex flex-wrap justify-content-center text-muted mt-3"></div></div></div></div><script src="https://cdn.jsdelivr.net/npm/mermaid@8/dist/mermaid.min.js"></script> <script> $(function() { function updateMermaid(event) { if (event.source === window && event.data && event.data.direction === ModeToggle.ID) { const mode = event.data.message; if (typeof mermaid === "undefined") { return; } let expectedTheme = (mode === ModeToggle.DARK_MODE? "dark" : "default"); let config = { theme: expectedTheme }; /* Re-render the SVG › <https://github.com/mermaid-js/mermaid/issues/311#issuecomment-332557344> */ $(".mermaid").each(function() { let svgCode = $(this).prev().children().html(); $(this).removeAttr("data-processed"); $(this).html(svgCode); }); mermaid.initialize(config); mermaid.init(undefined, ".mermaid"); } } let initTheme = "default"; if ($("html[data-mode=dark]").length > 0 || ($("html[data-mode]").length == 0 && window.matchMedia("(prefers-color-scheme: dark)").matches ) ) { initTheme = "dark"; } let mermaidConf = { theme: initTheme /* <default|dark|forest|neutral> */ }; /* Markdown converts to HTML */ $("pre").has("code.language-mermaid").each(function() { let svgCode = $(this).children().html(); $(this).addClass("unloaded"); $(this).after(`<div class=\"mermaid\">${svgCode}</div>`); }); mermaid.initialize(mermaidConf); window.addEventListener("message", updateMermaid); }); </script><div id="mask"></div><a id="back-to-top" href="#" aria-label="back-to-top" class="btn btn-lg btn-box-shadow" role="button"> <i class="fas fa-angle-up"></i> </a> <script src="https://cdn.jsdelivr.net/npm/simple-jekyll-search@1.10.0/dest/simple-jekyll-search.min.js"></script> <script> SimpleJekyllSearch({ searchInput: document.getElementById('search-input'), resultsContainer: document.getElementById('search-results'), json: '/assets/js/data/search.json', searchResultTemplate: '<div class="pl-1 pr-1 pl-sm-2 pr-sm-2 pl-lg-4 pr-lg-4 pl-xl-0 pr-xl-0"> <a href="{url}">{title}</a><div class="post-meta d-flex flex-column flex-sm-row text-muted mt-1 mb-1"> {categories} {tags}</div><p>{snippet}</p></div>', noResultsText: '<p class="mt-5">搜索结果为空</p>', templateMiddleware: function(prop, value, template) { if (prop === 'categories') { if (value === '') { return `${value}`; } else { return `<div class="mr-sm-4"><i class="far fa-folder fa-fw"></i>${value}</div>`; } } if (prop === 'tags') { if (value === '') { return `${value}`; } else { return `<div><i class="fa fa-tag fa-fw"></i>${value}</div>`; } } } }); </script> <script src="https://cdn.jsdelivr.net/combine/npm/magnific-popup@1/dist/jquery.magnific-popup.min.js,npm/lozad/dist/lozad.min.js,npm/clipboard@2/dist/clipboard.min.js"></script> <script src="https://cdn.jsdelivr.net/combine/npm/dayjs@1/dayjs.min.js,npm/dayjs@1/locale/zh.min.js,npm/dayjs@1/plugin/relativeTime.min.js,npm/dayjs@1/plugin/localizedFormat.min.js"></script> <script defer src="/assets/js/dist/post.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/bootstrap@4/dist/js/bootstrap.bundle.min.js"></script> <script defer src="/app.js"></script>
